| Персептрон для линейно разделимых 2D-точек.
| Задача: порождаем обучающую и тестовую выборки из квадрата [-1,1]^2.
| Истинная разметка задаётся случайной прямой a*x1 + b*x2 + c = 0.
| Чтобы гарантировать разделимость, отбрасываем точки ближе маржи δ к прямой.
| Обучаем персептрон по правилу Розенблатта и печатаем точность train/test.

алг main
нач
  | гиперпараметры
  цел Ntrain, Ntest, epochs
  вещ eta, delta
  вещ noise_te         | доля шума в метках теста (для нереализуемости 100%)
  Ntrain := 4000
  Ntest := 20000
  epochs := 50
  eta := 0.1
  delta := 0.1      | маржа для отбора точек
  noise_te := 0.01  | ~1% инвертируем метки на тесте

  | массивы данных
  вещ таб X1tr[0:Ntrain-1], X2tr[0:Ntrain-1], Ytr[0:Ntrain-1]
  вещ таб X1te[0:Ntest-1],  X2te[0:Ntest-1],  Yte[0:Ntest-1]

  | параметры прямой-учителя (a*x1 + b*x2 + c = 0)
  вещ la, lb, lc
  la := rand(-1.0, 1.0)
  lb := rand(-1.0, 1.0)
  lc := rand(-0.2, 0.2)
  | нормируем (не обязательно, просто косметика)
  вещ norm
  norm := sqrt(la*la + lb*lb)
  если norm <> 0.0 то
    la := la / norm
    lb := lb / norm
    lc := lc / norm
  все

  | генерация train с отбрасыванием по марже delta
  цел i
  вещ x1, x2, s, vabs, y
  i := 0
  нц пока i < Ntrain
    x1 := rand(-1.0, 1.0)
    x2 := rand(-1.0, 1.0)
    s := la*x1 + lb*x2 + lc
    vabs := s; если vabs < 0.0 то vabs := -vabs все
    если vabs >= delta то
      y := 1.0; если s < 0.0 то y := -1.0 все
      X1tr[i] := x1; X2tr[i] := x2; Ytr[i] := y
      i := i + 1
    все
  кц

  | генерация test
  i := 0
  нц пока i < Ntest
    x1 := rand(-1.0, 1.0)
    x2 := rand(-1.0, 1.0)
    s := la*x1 + lb*x2 + lc
    vabs := s; если vabs < 0.0 то vabs := -vabs все
    если vabs >= delta то
      y := 1.0; если s < 0.0 то y := -1.0 все
      | внесём небольшой шум в метки теста
      вещ r
      r := rand(0.0, 1.0)
      если r < noise_te то y := -y все
      X1te[i] := x1; X2te[i] := x2; Yte[i] := y
      i := i + 1
    все
  кц

  | модель: w ∈ R^2, bias
  вещ w1, w2, bias
  w1 := 0.0; w2 := 0.0; bias := 0.0

  | обучение персептрона
  цел e, mistakes
  вещ pred, margin
  нц для e от 0 до epochs-1
    mistakes := 0
    нц для i от 0 до Ntrain-1
      pred := w1*X1tr[i] + w2*X2tr[i] + bias
      margin := Ytr[i] * pred
      если margin <= 0.0 то
        w1 := w1 + eta * Ytr[i] * X1tr[i]
        w2 := w2 + eta * Ytr[i] * X2tr[i]
        bias := bias + eta * Ytr[i]
        mistakes := mistakes + 1
      все
    кц
    | если ошибок нет — выходим раньше
    если mistakes = 0 то выход все
  кц

  | точности
  вещ acc_tr, acc_te
  acc_tr := accuracy(Ntrain, X1tr, X2tr, Ytr, w1, w2, bias)
  acc_te := accuracy(Ntest,  X1te,  X2te,  Yte,  w1, w2, bias)

  вывод "perceptron: Ntrain=", Ntrain, ", Ntest=", Ntest, ", epochs=", epochs, ", eta=", eta, ", delta=", delta, нс
  вывод "teacher line: a=", la, ", b=", lb, ", c=", lc, нс
  вывод "train acc=", acc_tr, ", test acc=", acc_te, нс
кон

| --- Вспомогательные функции ---

| точность классификации при данных весах
алг вещ accuracy(цел n, вещ таб X1[0:n-1], вещ таб X2[0:n-1], вещ таб Y[0:n-1], вещ w1, вещ w2, вещ bias)
нач
  цел i, correct
  вещ pred, y, acc
  correct := 0
  нц для i от 0 до n-1
    pred := w1*X1[i] + w2*X2[i] + bias
    y := 1.0; если pred < 0.0 то y := -1.0 все
    если y = Y[i] то correct := correct + 1 все
  кц
  acc := (1.0 * correct) / n
  знач := acc
кон
